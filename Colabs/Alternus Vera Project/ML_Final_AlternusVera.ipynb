{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_Final_AlternusVera.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "xbyeiGyKdYnl",
        "k8fg9elTkCKl",
        "DT90w4Uvg09L",
        "rI3pnepkgbp3",
        "PCX6GliKvO7Z",
        "1HCvIsOUlARt",
        "QK370u6B433C",
        "D-CI1iHc0OQR",
        "ZjGRt3VClwUD",
        "nN0y5iinUdI6",
        "FG0a6lJXqxJl"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gowri-Rk/Machine-Learning/blob/master/Colabs/Alternus%20Vera%20Project/ML_Final_AlternusVera.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8dqeuWwqoQS",
        "colab_type": "text"
      },
      "source": [
        "**Final Alternus Vera notebook**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbyeiGyKdYnl",
        "colab_type": "text"
      },
      "source": [
        "# Problem Statement and Data Narrative"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6iCyseQdfYt",
        "colab_type": "text"
      },
      "source": [
        "Liar Liar Pants on Fire Dataset Description\n",
        "It has 3 files test, training and valid.\n",
        "\n",
        "Each file has 14 columns\n",
        "\n",
        "Column 1: the ID of the statement ([ID].json).\n",
        "\n",
        "Column 2: the label.\n",
        "\n",
        "Column 3: the statement.\n",
        "\n",
        "Column 4: the subject(s).\n",
        "\n",
        "Column 5: the speaker.\n",
        "\n",
        "Column 6: the speaker's job title.\n",
        "\n",
        "Column 7: the state info.\n",
        "\n",
        "Column 8: the party affiliation.\n",
        "\n",
        "Column 9-13: the total credit history count, including the current statement.\n",
        "\n",
        "Column 14: the context (venue / location of the speech or statement).\n",
        "\n",
        "Process\n",
        "Load the Data\n",
        "Distillation Process\n",
        "Data Cleaning and Text Preprocessing\n",
        "Visualization\n",
        "Chosen feature: Verifiable Authenticity\n",
        "\n",
        "Merge all features and individual contributions\n",
        "Form Polynomial Equation\n",
        "\n",
        "Enrichment Dataset Details\n",
        "SenticNet5 sensational words corpus\n",
        "Google News 3million words corpus for spell check\n",
        "PoliticalFact Fake news and Real News Content\n",
        "Spam Dictionary\n",
        "\n",
        "Libraries Used\n",
        "NLTK\n",
        "Gensim\n",
        "Numpy\n",
        "Pandas\n",
        "CSV\n",
        "WordCloud\n",
        "Seaborn\n",
        "Scipy\n",
        "Regualr Expression\n",
        "Matplotlib\n",
        "Sklearn\n",
        "What did I try and What worked?\n",
        "\n",
        "What did not work?\n",
        "\n",
        "What alternatives did you try?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8fg9elTkCKl",
        "colab_type": "text"
      },
      "source": [
        "# Verifiable Authenticity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIBHGl7PkKSa",
        "colab_type": "text"
      },
      "source": [
        "In today's world the fake news spreads faster than real news and its important to detect fake news in order to mitigate its negative effects. This project contains analysis and detection of fake news based on verifiable authenticity of the news statement.Authenticity is about how genuine the statement is. \n",
        "\n",
        "DataSets used:\n",
        "\n",
        "1. Liar Liar Dataset: Contains news statements classified as a range of values from True to PantsOnFire. \n",
        "2. Kaggle Fake News Dataset: Contains a binary classification of text and author\n",
        "\n",
        "**Feature: Verifiable Auntenticity**\n",
        "To classify a news as fake or real, one of the main steps is to find out whether the data can be verified as authentic or not. This involves:\n",
        "1. Checking the **source** of the news: News obtained from social media or memes tend to be fake. However, news reported by a genuine news publication can be trusted.\n",
        "\n",
        "**How**: Buzzfeed's dataset on website authenticity (amalgamate)\n",
        "\n",
        "2. **Credibility**: Some people might give deliberate misinformation to mislead readers. Its important to check the credibilty of the speaker as well as the author of the post.\n",
        "\n",
        "**How**: Check the past statements made by the speaker to see no. of his false/ true statements\n",
        "\n",
        "3. **False representation**: These are employed to catch the attention of viewers with false information.\n",
        "\n",
        "**How**: Cosine similarity with fake_news dataset on the text to match fake news statements\n",
        "\n",
        "4. **Verify whether other news agencies are reporting the same story**\n",
        "\n",
        "5. **Verify if the speaker or source stated the same as found in the news**\n",
        "\n",
        "\n",
        "**Method:** \n",
        "Encode the \"source\" column of liar liar dataset to fall into categories for Fake and Real news based on the source credibility.\n",
        "\n",
        "**Classification algorithms**: Naive Bayes, Decision Trees, SVM, Linear Regression, Logistic Regression\n",
        "\n",
        "What worked: Data cleaning, pre-processing and LDA topic modelling, distillation, classification\n",
        "\n",
        "What didn't work well: Data amalgamation with an other dataset that could enrich the current dataset to provide a stronger feature of authenticity. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKZ-em2bqvSD",
        "colab_type": "text"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHHRqsDCqtvD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "23758c05-db25-4e3c-803d-d0ace530b1fe"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "import gensim\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.pipeline import Pipeline\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('vader_lexicon')\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import sparse\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import tree\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import linear_model\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import classification_report,confusion_matrix, roc_curve, roc_auc_score, auc, accuracy_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1Yey1pZ5BEe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "f692dcd4-9611-4f46-ad62-a3183d842211"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/', force_remount = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vOPFfN2e-ZB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Read the train, test and validation dataset from Liar Dataset \n",
        "liar_test_filename =  '/content/gdrive/My Drive/MLSpring2020/datatribe-nutritionbasediseaseprediction/AlternusVera/Datasets/liar_dataset/test.tsv'\n",
        "liar_train_filename = '/content/gdrive/My Drive/MLSpring2020/datatribe-nutritionbasediseaseprediction/AlternusVera/Datasets/liar_dataset/train.tsv'\n",
        "liar_valid_filename = '/content/gdrive/My Drive/MLSpring2020/datatribe-nutritionbasediseaseprediction/AlternusVera/Datasets/liar_dataset/valid.tsv'\n",
        "\n",
        "\n",
        "colnames = ['jsonid', 'label', 'headline_text', 'subject', 'speaker', 'speakerjobtitle', 'stateinfo','partyaffiliation', 'barelytruecounts', 'falsecounts','halftruecounts','mostlytrueocunts','pantsonfirecounts','context']\n",
        "\n",
        "df_liar_train = pd.read_csv(liar_train_filename, sep='\\t', names = colnames, error_bad_lines=False)\n",
        "df_liar_test = pd.read_csv(liar_test_filename, sep='\\t', names = colnames, error_bad_lines=False)\n",
        "df_liar_val = pd.read_csv(liar_valid_filename, sep='\\t', names = colnames, error_bad_lines=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RRfVDJMfNrA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "e0bc03d5-e2fd-4310-8daa-54695100b43c"
      },
      "source": [
        "# Display check the dimensions and the first 2 rows of the file.\n",
        "\n",
        "print('train dim:',df_liar_train.shape, 'test dim:', df_liar_test.shape)\n",
        "df_liar_train.iloc[0:2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train dim: (10240, 14) test dim: (1267, 14)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>jsonid</th>\n",
              "      <th>label</th>\n",
              "      <th>headline_text</th>\n",
              "      <th>subject</th>\n",
              "      <th>speaker</th>\n",
              "      <th>speakerjobtitle</th>\n",
              "      <th>stateinfo</th>\n",
              "      <th>partyaffiliation</th>\n",
              "      <th>barelytruecounts</th>\n",
              "      <th>falsecounts</th>\n",
              "      <th>halftruecounts</th>\n",
              "      <th>mostlytrueocunts</th>\n",
              "      <th>pantsonfirecounts</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2635.json</td>\n",
              "      <td>false</td>\n",
              "      <td>Says the Annies List political group supports ...</td>\n",
              "      <td>abortion</td>\n",
              "      <td>dwayne-bohac</td>\n",
              "      <td>State representative</td>\n",
              "      <td>Texas</td>\n",
              "      <td>republican</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>a mailer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10540.json</td>\n",
              "      <td>half-true</td>\n",
              "      <td>When did the decline of coal start? It started...</td>\n",
              "      <td>energy,history,job-accomplishments</td>\n",
              "      <td>scott-surovell</td>\n",
              "      <td>State delegate</td>\n",
              "      <td>Virginia</td>\n",
              "      <td>democrat</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>a floor speech.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       jsonid      label  ... pantsonfirecounts          context\n",
              "0   2635.json      false  ...               0.0         a mailer\n",
              "1  10540.json  half-true  ...               0.0  a floor speech.\n",
              "\n",
              "[2 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vi2TvtCPqyzn",
        "colab_type": "text"
      },
      "source": [
        "# Data preparation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMeI5sThfaGC",
        "colab_type": "text"
      },
      "source": [
        "**Steps included in the preprocessing:**\n",
        "\n",
        "\n",
        "\n",
        "*   Remove Special Characters and Punctuations\n",
        "\n",
        "*   Lower case the news\n",
        "*   Tokenization\n",
        "*   Remove Stop Words\n",
        "*   Lemmatization\n",
        "* Stemming\n",
        "* Spell Check"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DT90w4Uvg09L",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2258yblSq1Ve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "def cleaning(raw_news):\n",
        "    import nltk\n",
        "    \n",
        "    # 1. Remove non-letters/Special Characters and Punctuations\n",
        "    news = re.sub(\"[^a-zA-Z]\", \" \", raw_news)\n",
        "    \n",
        "    # 2. Convert to lower case.\n",
        "    news =  news.lower()\n",
        "    \n",
        "    # 3. Tokenize.\n",
        "    news_words = nltk.word_tokenize( news)\n",
        "    \n",
        "    # 4. Convert the stopwords list to \"set\" data type.\n",
        "    stops = set(nltk.corpus.stopwords.words(\"english\"))\n",
        "    \n",
        "    # 5. Remove stop words. \n",
        "    words = [w for w in  news_words  if not w in stops]\n",
        "    \n",
        "    # 6. Lemmentize \n",
        "    wordnet_lem = [ WordNetLemmatizer().lemmatize(w) for w in words ]\n",
        "    \n",
        "    # 7. Stemming\n",
        "    stems = [nltk.stem.SnowballStemmer('english').stem(w) for w in wordnet_lem ]\n",
        "    \n",
        "    # 8. Join the stemmed words back into one string separated by space, and return the result.\n",
        "    return \" \".join(stems)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUGwJoADf_Qx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10e3ea8e-f908-4a2c-ffd1-44f76e4443f6"
      },
      "source": [
        "import time\n",
        "# clean training and test data \n",
        "# create new column \"tokenized\"\n",
        "t1 = time.time()\n",
        "\n",
        "# Add the processed data to the original data. \n",
        "# Perhaps using apply function would be more elegant and concise than using for loop\n",
        "df_liar_train['clean'] = df_liar_train[\"headline_text\"].apply(cleaning) \n",
        "\n",
        "t2 = time.time()\n",
        "print(\"\\nTime to clean, tokenize and stem train data: \\n\", len(df_liar_train), \"news:\", (t2-t1)/60, \"min\")\n",
        "\n",
        "t1 = time.time()\n",
        "df_liar_test['clean'] = df_liar_test[\"headline_text\"].apply(cleaning)\n",
        "\n",
        "t2 = time.time()\n",
        "print(\"\\n\\nTime to clean, tokenize and stem test data: \\n\", len(df_liar_test), \"news:\", (t2-t1)/60, \"min\")\n",
        "\n",
        "t1 = time.time()\n",
        "df_liar_val['clean'] = df_liar_val[\"headline_text\"].apply(cleaning)\n",
        "\n",
        "t2 = time.time()\n",
        "print(\"\\n\\nTime to clean, tokenize and stem valid data: \\n\", len(df_liar_val), \"news:\", (t2-t1)/60, \"min\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Time to clean, tokenize and stem train data: \n",
            " 10240 news: 0.1032333254814148 min\n",
            "\n",
            "\n",
            "Time to clean, tokenize and stem test data: \n",
            " 1267 news: 0.010376377900441488 min\n",
            "\n",
            "\n",
            "Time to clean, tokenize and stem valid data: \n",
            " 1284 news: 0.010247898101806641 min\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rI3pnepkgbp3",
        "colab_type": "text"
      },
      "source": [
        "## Google News corpus word2vec Spell Check\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uur59u_LUdGx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "outputId": "565d4682-890e-4d4e-c7c4-effb79a7f5fa"
      },
      "source": [
        "model = gensim.models.KeyedVectors.load_word2vec_format('input_data/GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
        "words = model.index2word\n",
        "\n",
        "w_rank = {}\n",
        "for i,word in enumerate(words):\n",
        "    w_rank[word] = i\n",
        "\n",
        "WORDS = w_rank"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-2fd59537c2fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'input_data/GoogleNews-vectors-negative300.bin.gz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex2word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mw_rank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[1;32m   1436\u001b[0m         return _load_word2vec_format(\n\u001b[1;32m   1437\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1438\u001b[0;31m             limit=limit, datatype=datatype)\n\u001b[0m\u001b[1;32m   1439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_keras_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/utils_any2vec.py\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loading projection weights from %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmart_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m         \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# throws for invalid file format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36msmart_open\u001b[0;34m(uri, mode, **kw)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     return open(uri, mode, ignore_ext=ignore_extension,\n\u001b[0;32m--> 309\u001b[0;31m                 transport_params=transport_params, **scrubbed_kwargs)\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, ignore_ext, transport_params)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0mbinary_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_TO_BINARY_LUT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m     \u001b[0mbinary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_binary_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransport_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mignore_ext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mdecompressed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36m_open_binary_stream\u001b[0;34m(uri, mode, transport_params)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[0mscheme\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sniff_scheme\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0msubmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_transport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscheme\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m     \u001b[0mfobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_uri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransport_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TODO'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/smart_open/local_file.py\u001b[0m in \u001b[0;36mopen_uri\u001b[0;34m(uri_as_string, mode, transport_params)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mopen_uri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri_as_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransport_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mparsed_uri\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_uri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri_as_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mfobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_uri\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'uri_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'input_data/GoogleNews-vectors-negative300.bin.gz'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvTV6F-uUdG0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "def words(text): return re.findall(r'\\w+', text.lower())\n",
        "\n",
        "def P(word, N=sum(WORDS.values())): \n",
        "    \"Probability of `word`.\"\n",
        "    return - WORDS.get(word, 0)\n",
        "\n",
        "def correction(word): \n",
        "    \"Most probable spelling correction for word.\"\n",
        "    return max(candidates(word), key=P)\n",
        "\n",
        "def candidates(word): \n",
        "    \"Generate possible spelling corrections for word.\"\n",
        "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
        "\n",
        "def known(words): \n",
        "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
        "    return set(w for w in words if w in WORDS)\n",
        "\n",
        "def edits1(word):\n",
        "    \"All edits that are one edit away from `word`.\"\n",
        "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
        "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
        "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
        "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
        "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
        "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
        "    return set(deletes + transposes + replaces + inserts)\n",
        "\n",
        "def edits2(word): \n",
        "    \"All edits that are two edits away from `word`.\"\n",
        "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7owQDH4UdG3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def spell_checker(text):\n",
        "    all_words = re.findall(r'\\w+', text.lower()) # split sentence to words\n",
        "    spell_checked_text  = []\n",
        "    for i in range(len(all_words)):\n",
        "        spell_checked_text.append(correction(all_words[i]))\n",
        "    return ' '.join(spell_checked_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwspyI2hUdG6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Before: \\n\", train_news['clean'][0] )\n",
        "t1 = time.time()\n",
        "train_news['clean'] = train_news['clean'].apply(spell_checker)\n",
        "t2 = time.time()\n",
        "print(\"\\nTime to spell check the train data: \\n\", len(train_news), \"news:\", (t2-t1)/60, \"min\")\n",
        "\n",
        "print(\"\\nAfter: \\n\",train_news['clean'][0] )\n",
        "train_news.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIueMn0bUdG9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t1 = time.time()\n",
        "test_news['clean'] = test_news['clean'].apply(spell_checker)\n",
        "test_news.head(5)\n",
        "t2 = time.time()\n",
        "print(\"\\nTime to spell check the test data: \\n\", len(test_news), \"news:\", (t2-t1)/60, \"min\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_J56NW4FUdHY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t1 = time.time()\n",
        "valid_news['clean'] = valid_news['clean'].apply(spell_checker)\n",
        "valid_news.head(5)\n",
        "t2 = time.time()\n",
        "print(\"\\nTime to spell check the valid data: \\n\", len(valid_news), \"news:\", (t2-t1)/60, \"min\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OGfxi9XUdHd",
        "colab_type": "text"
      },
      "source": [
        "##### Saved the trained dataset into a seperate CSV file "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHfq6jCaUdHd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_news.to_csv(\"input_data/train_processed.csv\", sep=',')\n",
        "test_news.to_csv(\"input_data/test_processed.csv\", sep=',')\n",
        "valid_news.to_csv(\"input_data/valid_processed.csv\", sep=',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCX6GliKvO7Z",
        "colab_type": "text"
      },
      "source": [
        "## Encoding string features to float to be able to run various algorithms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MWn4xWHJv2Pg",
        "colab": {}
      },
      "source": [
        "df_liar_train = pd.read_csv(\"/content/gdrive/My Drive/MLSpring2020/datatribe-nutritionbasediseaseprediction/AlternusVera/Datasets/Rimzim/train_processed.csv\")\n",
        "df_liar_test = pd.read_csv(\"/content/gdrive/My Drive/MLSpring2020/datatribe-nutritionbasediseaseprediction/AlternusVera/Datasets/Rimzim/test_processed.csv\")\n",
        "df_liar_val = pd.read_csv(\"/content/gdrive/My Drive/MLSpring2020/datatribe-nutritionbasediseaseprediction/AlternusVera/Datasets/Rimzim/valid_processed.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kltoJMl19HfN",
        "colab_type": "text"
      },
      "source": [
        "Merging training and validation datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mN6T7kcX9Gep",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# concatenate validation data with training data\n",
        "# df_liar_train = pd.concat([df_liar_val])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFPrulz_yRh1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_liar_train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaVbPDys9eGK",
        "colab_type": "text"
      },
      "source": [
        "We have a lot of columns with string datatypes, we will have to encode that into integer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpBn3VhfRGaD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#list of categorical features\n",
        "categoricalVariables = ['label'\t,'headline_text',\t'subject',\t'speaker', \t'speakerjobtitle', \t'stateinfo',\t'partyaffiliation', 'context']\n",
        "numericalVariables = ['barelytruecounts',\t'falsecounts',\t'halftruecounts',\t'mostlytrueocunts',\t'pantsonfirecounts']\n",
        "\n",
        "# d = defaultdict(preprocessing.LabelEncoder)\n",
        "le = preprocessing.LabelEncoder()\n",
        "df_liar_train[categoricalVariables] = df_liar_train[categoricalVariables].applymap(str)\n",
        "\n",
        "# encoded_data = df_liar_train[categoricalVariables].apply(lambda x: d[x.name].fit_transform(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HemCdzmG7Mw7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoded_data = df_liar_train[categoricalVariables].apply(lambda col: le.fit_transform(col.astype(str)), axis=0, result_type='expand')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJUZCuTpK0YA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#encoding test dataset\n",
        "df_liar_test[categoricalVariables] = df_liar_test[categoricalVariables].applymap(str)\n",
        "encoded_test_data = df_liar_test[categoricalVariables].apply(lambda col: le.fit_transform(col.astype(str)), axis=0, result_type='expand')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3n_9xVmxDFlB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_liar_train_enc = pd.concat([df_liar_train[numericalVariables], encoded_data], axis=1)\n",
        "df_liar_test_enc = pd.concat([df_liar_test[numericalVariables], encoded_test_data], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woKZjUaLDYWF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_liar_train_enc.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HCvIsOUlARt",
        "colab_type": "text"
      },
      "source": [
        "#  Data Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hn8CSsnElMlA",
        "colab_type": "text"
      },
      "source": [
        "Exploring the datasets to get a better understanding of the distribuitions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1T4tX28g6xK",
        "colab_type": "text"
      },
      "source": [
        "## Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkGSmlqphYR-",
        "colab_type": "text"
      },
      "source": [
        "Word clouds help us visualize words with high frequencies in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4d21o1Gg8sF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaCio83Bhj6w",
        "colab_type": "text"
      },
      "source": [
        "Training data word cloud"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiDvvFKThBLc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cloud(data,backgroundcolor = 'white', width = 800, height = 600):\n",
        "    wordcloud = WordCloud(stopwords = STOPWORDS, background_color = backgroundcolor,\n",
        "                         width = width, height = height).generate(data)\n",
        "    plt.figure(figsize = (15, 10))\n",
        "    plt.imshow(wordcloud)\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "    \n",
        "cloud(' '.join(df_liar_train['clean']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thUSsAQ8hmaX",
        "colab_type": "text"
      },
      "source": [
        "testing data word cloud"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsjkZvdohLN_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cloud(' '.join(df_liar_test['clean']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytsUUNlchoU6",
        "colab_type": "text"
      },
      "source": [
        "validation data word cloud"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4117bJqhRJH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cloud(' '.join(df_liar_val['clean']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlfiTnbX1gim",
        "colab_type": "text"
      },
      "source": [
        "##  Visualizing the factors for feature: Verifiable Authenticity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyXqtZQS48cb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "liar_col = ['id',\t'label'\t,'statement',\t'subject',\t'speaker', \t'job', \t'state',\t'party',\t'barely_true',\t'false',\t'half_true',\t'mostly_true',\t'pants_on_fire',\t'venue']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xsri6puo2P6c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_liar_train = pd.read_csv(\"/content/gdrive/My Drive/MLSpring2020/datatribe-nutritionbasediseaseprediction/AlternusVera/Datasets/Rimzim/train_processed.csv\")\n",
        "df_liar_test = pd.read_csv(\"/content/gdrive/My Drive/MLSpring2020/datatribe-nutritionbasediseaseprediction/AlternusVera/Datasets/Rimzim/test_processed.csv\")\n",
        "df_liar_val = pd.read_csv(\"/content/gdrive/My Drive/MLSpring2020/datatribe-nutritionbasediseaseprediction/AlternusVera/Datasets/Rimzim/valid_processed.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVIJm1eVe4DP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_liar_train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Td-5J03b3lnd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df_liar_test = pd.read_csv(\"/content/gdrive/My Drive/MLSpring2020/datatribe-nutritionbasediseaseprediction/AlternusVera/Datasets/liar_dataset/test.tsv\", names=liar_col, sep = \"\\t\")\n",
        "# df_liar_val = pd.read_csv(\"/content/gdrive/My Drive/MLSpring2020/datatribe-nutritionbasediseaseprediction/AlternusVera/Datasets/liar_dataset/valid.tsv\", names=liar_col, sep = \"\\t\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgZc1CPPsbvG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_liar_train.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNINPNb3b8uk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Liar Liar Dataset\n",
        "label_distribution = df_liar_train.groupby(\"label\").count()\n",
        "label_distribution = label_distribution[[\"jsonid\"]]\n",
        "label_distribution.columns = [\"Count\"]\n",
        "label_distribution = label_distribution.transpose()[['pants-fire', 'false', 'barely-true', 'half-true', 'mostly-true', 'true']].transpose()\n",
        "ax = label_distribution.plot(kind='bar', figsize = (15, 5))\n",
        "#label_distribution"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0BLdOPIfXEj",
        "colab_type": "text"
      },
      "source": [
        "Plotting various distribuitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NBZmmaWfWbE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def get_truth_distribution(data, col_name, count_threshold, normalize = True):\n",
        "    df = data[[col_name, \"jsonid\", \"label\"]]\n",
        "    df.columns = [col_name, \"Percent\", \"label\"]\n",
        "    col_subject = df.groupby([col_name, \"label\"]).count()[[\"Percent\"]]\n",
        "    col_subject = col_subject.unstack('label')\n",
        "    col_subject = col_subject.fillna(0)\n",
        "    col_subject = col_subject[[('Percent', 'pants-fire'),\n",
        "                               ('Percent', 'false'),\n",
        "                               ('Percent', 'barely-true'),\n",
        "                               ('Percent', 'half-true'),\n",
        "                               ('Percent', 'mostly-true'),\n",
        "                               ('Percent', 'true')]]\n",
        "    col_subject = col_subject[col_subject.sum(axis = 1) >= count_threshold]\n",
        "    if normalize == True:\n",
        "        col_subject = col_subject.div(col_subject.sum(axis = 1),axis = 'index')\n",
        "    col_subject = col_subject.sort_values(by=[('Percent', 'pants-fire')], ascending = False)\n",
        "    return col_subject"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ecnp-CDeizX",
        "colab_type": "text"
      },
      "source": [
        "Are statements in debates more likely to be lies, compared to other speeches?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQh12ZtUejkm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "debate = df_liar_train[df_liar_train[\"context\"] == \"a debate.\"]\n",
        "debate_distribution = get_truth_distribution(debate, \"context\", 10)\n",
        "\n",
        "plt.style.use('ggplot')\n",
        "groups = debate_distribution.columns.get_level_values(1).tolist()\n",
        "ind = np.arange(len(groups))  # the x locations for the groups\n",
        "ax = debate_distribution.plot(width=0.5,\n",
        "                              kind='bar',\n",
        "                              ec='black',\n",
        "                              figsize=(8,5))\n",
        "\n",
        "plt.title('Truth distribution for statements in debates')\n",
        "plt.ylabel('Percentage')\n",
        "\n",
        "ax.legend(groups)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27uhEJXZhIMv",
        "colab_type": "text"
      },
      "source": [
        " Compare distribution of fake news between traditional press, speeches and social media"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCqcweEUhMFa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "context_distribution = get_truth_distribution(df_liar_train, \"context\", 70, normalize = True) \n",
        "context_distribution.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oCGPH6RhXKJ",
        "colab_type": "text"
      },
      "source": [
        "**Social Media**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNEbxdcDhZhh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "social_media_regex = re.compile(r'\\b(Facebook|blog|twitter|my space|newsletter|video|email|tweet|social media|YouTube)[s]*\\b' ,re.I)\n",
        "social_media_sets = context_distribution[context_distribution.index.str.contains(social_media_regex, regex=True) == True]\n",
        "plt.style.use('ggplot')\n",
        "groups = social_media_sets.columns.get_level_values(1).tolist()\n",
        "ind = np.arange(len(groups))  # the x locations for the groups\n",
        "ax = social_media_sets.plot(width=0.5,\n",
        "                              kind='bar',\n",
        "                              ec='black',\n",
        "                              figsize=(8,5))\n",
        "\n",
        "plt.title('Truth distribution in social media')\n",
        "plt.ylabel('Percentage')\n",
        "\n",
        "ax.legend(groups)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QK370u6B433C",
        "colab_type": "text"
      },
      "source": [
        "# Common Functions: for evaluation metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fP08phsnylJk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to get roc curve\n",
        "def get_roc (y_test,y_pred):\n",
        "    # Compute ROC curve and ROC area for each class\n",
        "    fpr = dict()\n",
        "    tpr = dict()\n",
        "    roc_auc = dict()\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    #Plot of a ROC curve\n",
        "    plot.figure()\n",
        "    lw = 2\n",
        "    plot.plot(fpr, tpr, color='darkorange',\n",
        "             label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "    plot.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "    plot.xlim([0.0, 1.0])\n",
        "    plot.ylim([0.0, 1.0])\n",
        "    plot.xlabel('False Positive Rate')\n",
        "    plot.ylabel('True Positive Rate')\n",
        "    plot.title('Receiver operating characteristic')\n",
        "    plot.legend(loc=\"upper left\")\n",
        "    plot.show()\n",
        "    return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auIuHTta5GhZ",
        "colab_type": "text"
      },
      "source": [
        "# Common Classification and regression functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4viJf3JPZby",
        "colab_type": "text"
      },
      "source": [
        "We will create common functions for all algorithms, to be able to run them by just passing different training and testing data without code duplication -  - pass xtrain, ytrain, xtest, ytest as parameters to run the algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tW7a9bUTMSp7"
      },
      "source": [
        "Naive Bayes Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_22vvOADMSp8",
        "colab": {}
      },
      "source": [
        "def NBClassifier(xtrain, ytrain, xtest, ytest):\n",
        "  gnb = GaussianNB()\n",
        "  gnb.fit(xtrain,ytrain)\n",
        "  predicted = gnb.predict(xtest)\n",
        "  print(classification_report(ytest, predicted))\n",
        "  cnfmtx=confusion_matrix(ytest, predicted)\n",
        "  print(\"Confusion matrix:\\n\",cnfmtx)\n",
        "\n",
        "  print(\"Mean squared error: %.2f\" %mean_squared_error(ytest, predicted))\n",
        "  print(\"Mean absolute error: %.2f\" %mean_absolute_error(ytest, predicted))\n",
        "  print('Root Mean Squared Error: %.2f ' %np.sqrt(mean_squared_error(ytest, predicted)))\n",
        "  print('Accuracy :', accuracy_score(ytest, predicted))\n",
        "  get_roc(ytest, predicted)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "D8UHOmVOMSqA"
      },
      "source": [
        "**Decision Tree Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8dsEuGAhMSqB",
        "colab": {}
      },
      "source": [
        "def DTreesClassifier(xtrain, ytrain, xtest, ytest):\n",
        "  clf = tree.DecisionTreeClassifier()\n",
        "  clf = clf.fit(xtrain,ytrain)\n",
        "  predicted=clf.predict(xtest)\n",
        "  cnfmtx=confusion_matrix(ytest, predicted)\n",
        "  print(\"Confusion matrix:\\n\",cnfmtx)\n",
        "\n",
        "  print(\"Mean squared error: %.2f\" %mean_squared_error(ytest, predicted))\n",
        "  print(\"Mean absolute error: %.2f\" %mean_absolute_error(ytest, predicted))\n",
        "  print('Root Mean Squared Error: %.2f ' %np.sqrt(mean_squared_error(ytest, predicted)))\n",
        "  print('Accuracy :', accuracy_score(ytest, predicted))\n",
        "  get_roc(ytest, predicted)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pV3et2XGMSqF"
      },
      "source": [
        "**Support Vector Machines**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Luc-CyhJMSqG",
        "colab": {}
      },
      "source": [
        "def SVMClassifier(X_train,Y_train,X_test,Y_test):\n",
        "  model = SVC()\n",
        "  model.fit(X_train,Y_train)\n",
        "  predicted = model.predict(X_test)\n",
        "  print(classification_report(Y_test, predicted))\n",
        "  cnfmtx=confusion_matrix(Y_test, predicted)\n",
        "  print(\"Confusion matrix:\\n\",cnfmtx)\n",
        "\n",
        "  print(\"Mean squared error: %.2f\" %mean_squared_error(Y_test, predicted))\n",
        "  print(\"Mean absolute error: %.2f\" %mean_absolute_error(Y_test, predicted))\n",
        "  print('Root Mean Squared Error: %.2f ' %np.sqrt(mean_squared_error(Y_test, predicted)))\n",
        "  get_roc(Y_test, predicted)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KKBEPK4iMSqJ"
      },
      "source": [
        "**Linear Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mMSrPav4MSqK",
        "colab": {}
      },
      "source": [
        "def LinRegClassifier(X_train,Y_train,X_test,Y_test):\n",
        "  regressor = LinearRegression()\n",
        "  regressor.fit(X_train,Y_train)\n",
        "\n",
        "  predicted = regressor.predict(X_test)\n",
        "  print(\"Mean squared error: %.2f\" %mean_squared_error(Y_test, predicted))\n",
        "  print(\"Mean absolute error: %.2f\" %mean_absolute_error(Y_test, predicted))\n",
        "  print('Root Mean Squared Error: %.2f ' %np.sqrt(mean_squared_error(Y_test, predicted)))\n",
        "  get_roc(Y_test, predicted)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ES3weiX25JsV",
        "colab_type": "text"
      },
      "source": [
        "Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JJserTeNxLL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def LogRegression(X_train,Y_train,X_test,Y_test):\n",
        "  logClassifier = linear_model.LogisticRegression(solver='liblinear', C=1, random_state=111)\n",
        "  logClassifier.fit(X_train, Y_train)\n",
        "  predicted = logClassifier.predict(X_test)\n",
        "\n",
        "  from sklearn import metrics\n",
        "  print(\"accuracy=\", metrics.accuracy_score(Y_test, predicted))\n",
        "  get_roc(Y_test, predicted)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-CI1iHc0OQR",
        "colab_type": "text"
      },
      "source": [
        "# Converting characters to numerical vectors using Gensim Word2Vec "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwpSYNT50WUg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenstrain = [nl.word_tokenize(sentences) for sentences in df_liar_train['headline_text']]\n",
        "tokenstest = [nl.word_tokenize(sentences) for sentences in df_liar_test['headline_text']]\n",
        "\n",
        "headline = [nl.word_tokenize(sentences) for sentences in df_liar_train['headline_text']]\n",
        "headlinetest =   [nl.word_tokenize(sentences) for sentences in df_liar_test['headline_text']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33m_qK6j01s-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = gensim.models.Word2Vec(tokenstrain, size=300, min_count=1, workers=4)\n",
        "print(\"\\n Training the word2vec model...\\n\")\n",
        "model.train(tokens, total_examples=len(tokens), epochs=100)\n",
        "model.wv.syn0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7H3iKnQG-Gz_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2 = gensim.models.Word2Vec(tokenstest, size=300, min_count=1, workers=4)\n",
        "print(\"\\n Training the word2vec model...\\n\")\n",
        "model2.train(tokens, total_examples=len(tokens), epochs=100)\n",
        "model2.wv.syn0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeI697OG1xMF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_liar_train_wv = pd.DataFrame(model.wv.syn0)\n",
        "df_liar_test_wv = pd.DataFrame(model2.wv.syn0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sq4Rdtll1-bn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_liar_train_wv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tH4wDKy3_m5Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpusLiar = []\n",
        "for i in df_liar_train['headline_text']:\n",
        "    corpusLiar.append(i)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvMLlpsf_sRN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidfVec = TfidfVectorizer(max_features=1000)\n",
        "\n",
        "tfidf_liar = tfidfVec.fit_transform(corpusLiar)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IKZWxmI_vhe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjGRt3VClwUD",
        "colab_type": "text"
      },
      "source": [
        "# 1. Feature Importance \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHOcGRZlpnh6",
        "colab_type": "text"
      },
      "source": [
        "Random forests are among the most popular machine learning methods. They provide relatively good accuracy, robustness and ease of use. They also provide two methods for feature selection: **mean decrease impurity and mean decrease accuracy.**\n",
        "\n",
        "---\n",
        "Random forest consists of a number of decision trees. Every node in the decision trees is a condition on a single feature, designed to split the dataset into two so that similar response values end up in the same set.For classification, it is typically either Gini impurity or information gain/entropy and for regression trees it is variance.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HR3ef1rx80Gj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_liar_train_enc.dropna(axis=0, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZrtwAGU843U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_liar_test_enc.dropna(axis=0, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtuyPYtxqbE7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#reading our Liar Liar dataset into new variables to run Random Forests\n",
        "xtrain_rf = df_liar_train_enc.iloc[:,3:-1]\n",
        "ytrain_rf = df_liar_train_enc['label']\n",
        "xtest_rf = df_liar_test_enc.iloc[:,3:-1]\n",
        "ytest_rf = df_liar_test_enc['label']\n",
        "colnames = ['headline_text', 'subject', 'speaker', 'speakerjobtitle', 'stateinfo','partyaffiliation', 'barelytruecounts', 'falsecounts','halftruecounts','mostlytrueocunts','pantsonfirecounts','context', 'clean']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88AWgcLlqGlM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import numpy as np\n",
        "\n",
        "# names=['barelytruecounts', 'falsecounts','halftruecounts','mostlytrueocunts','pantsonfirecounts']\n",
        "rf = RandomForestRegressor()\n",
        "rf.fit(xtrain_rf, ytrain_rf)\n",
        "print(\"Features sorted by their score:\")\n",
        "print(sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), colnames), \n",
        "             reverse=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fqvu1SedAj5j",
        "colab_type": "text"
      },
      "source": [
        "# MultiClass Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZENEeayBAkhd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert text to word count vectors with CountVectorizer\n",
        "# create the transform\n",
        "cvec = CountVectorizer()\n",
        "\n",
        "# tokenize, build vocab and encode training data\n",
        "traindata_cvec = cvec.fit_transform(df_liar_train['headline_text'].values)\n",
        "\n",
        "# summarize\n",
        "print(cvec.vocabulary_)\n",
        "# print(cvec.get_feature_names())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ai3EFoKuAoU7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# summarize encoded vector\n",
        "print(traindata_cvec.shape)\n",
        "print(type(traindata_cvec))\n",
        "print(traindata_cvec.toarray())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpJnQuuoBIrf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# import necessary packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer #for stemming\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk.corpus\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import  LogisticRegression\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import learning_curve\n",
        "from sklearn.metrics import confusion_matrix, f1_score, classification_report\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import average_precision_score\n",
        "from sklearn import svm\n",
        "\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zwN3P9LA_Ed",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Calculate inverse document frequencies\n",
        "# create the transform\n",
        "tfidf_vec = TfidfTransformer()\n",
        "\n",
        "# tokenize, build vocab and encode training data\n",
        "traindata_tfidf_vec = tfidf_vec.fit_transform(traindata_cvec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AyAMUe5BDLV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# tfidf score\n",
        "tfidf_vec.transform(traindata_cvec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVEX4nAdBQF0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# summarize encoded vector\n",
        "print(traindata_tfidf_vec.shape)\n",
        "print(traindata_tfidf_vec.toarray())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vn3umH-HBRx8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tfidf + ngrams\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1,2), use_idf=True, smooth_idf=True)\n",
        "tfidf_vectorizer_vectors = tfidf_vectorizer.fit_transform(df_liar_train['headline_text'].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsrWUHlFBUIf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# print(tfidf_ngram.toarray())\n",
        "# tfidf.vocabulary_\n",
        "first_vector_tfidfvectorizer = tfidf_vectorizer_vectors[0]\n",
        "\n",
        "\n",
        "# place tf-idf values in a pandas data frame\n",
        "df = pd.DataFrame(first_vector_tfidfvectorizer.T.todense(), index=tfidf_vectorizer.get_feature_names(), columns=[\"tfidf\"])\n",
        "df.sort_values(by=[\"tfidf\"],ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iukusp58BcH9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "nltk.download('treebank')\n",
        "nltk.download('universal_tagset')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwchkX6mBfMy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# POS tagging using CRF\n",
        "tagged_sentence = nltk.corpus.treebank.tagged_sents(tagset='universal')\n",
        "# print(len(tagged_sentence))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3LwPEjxBhrq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_sentences = df_liar_train['headline_text']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzCUfs2SBtwh",
        "colab_type": "text"
      },
      "source": [
        "MultiClass Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDo1HcPBBj4u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# using LogisticRegression\n",
        "logReg_pipeline_cv = Pipeline([\n",
        "    ('LogRCV', cvec),\n",
        "    ('LogR_model', LogisticRegression())\n",
        "])\n",
        "\n",
        "logReg_pipeline_cv.fit(df_liar_train['headline_text'], df_liar_train['label'])\n",
        "predictions_logReg = logReg_pipeline_cv.predict(df_liar_test['headline_text'])\n",
        "logReg_cv = np.mean(predictions_logReg == df_liar_test['label'])\n",
        "\n",
        "# using SVM\n",
        "svm_pipeline_cv = Pipeline([\n",
        "    ('svmCV', cvec),\n",
        "    ('svm_model', svm.LinearSVC())\n",
        "])\n",
        "\n",
        "svm_pipeline_cv.fit(df_liar_train['headline_text'], df_liar_train['label'])\n",
        "predictions_svm = svm_pipeline_cv.predict(df_liar_test['headline_text'])\n",
        "svm_cv = np.mean(predictions_svm == df_liar_test['label'])\n",
        "\n",
        "# using naive bayes\n",
        "nb_pipeline_cv = Pipeline([\n",
        "    ('nbCV', cvec),\n",
        "    ('nb_model', MultinomialNB())\n",
        "])\n",
        "\n",
        "nb_pipeline_cv.fit(df_liar_train['headline_text'], df_liar_train['label'])\n",
        "predictions_nb = nb_pipeline_cv.predict(df_liar_test['headline_text'])\n",
        "nb_cv = np.mean(predictions_nb == df_liar_test['label'])\n",
        "\n",
        "# using random forest\n",
        "rf_pipeline_cv = Pipeline([\n",
        "    ('rfCV', cvec),\n",
        "    ('rf_model', RandomForestClassifier(n_estimators=400, n_jobs=4))\n",
        "])\n",
        "\n",
        "rf_pipeline_cv.fit(df_liar_train['headline_text'], df_liar_train['label'])\n",
        "predictions_rf = rf_pipeline_cv.predict(df_liar_test['headline_text'])\n",
        "rf_cv = np.mean(predictions_rf == df_liar_test['label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lw4huO8WBxsa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(logReg_cv)\n",
        "print(svm_cv)\n",
        "print(nb_cv)\n",
        "print(rf_cv)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGDXJ3pcBUdZ",
        "colab_type": "text"
      },
      "source": [
        "# Named Entity Recognition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_YO6UvwBWs9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag import pos_tag\n",
        "import pandas as pd\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npj5ynn6B3If",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(sent):\n",
        "    sent = nltk.word_tokenize(sent)\n",
        "    sent = nltk.pos_tag(sent)\n",
        "    return sent"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmPpFs2SCJ92",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_liar_train['TokenizedContext'] = df_liar_train['context'].apply(lambda x: preprocess(str(x))) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgxKoFXqDQST",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_liar_train[['context', 'TokenizedContext']]\n",
        "#part of speech tagging"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9KLBzyMD8Aa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pattern = 'NP: {<DT>?<JJ>*<NN>}'\n",
        "\n",
        "cp = nltk.RegexpParser(pattern)\n",
        "\n",
        "def RegexpParser(sent):\n",
        "  cs = cp.parse(sent)\n",
        "  return cs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMhD3EgbhuPn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_liar_train['TokenizedContext'] = df_liar_train['TokenizedContext'].apply(lambda x: RegexpParser(x)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCal80mKicjF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.chunk import conlltags2tree, tree2conlltags\n",
        "\n",
        "df_liar_train['iob_tagged_context'] = df_liar_train['TokenizedContext'].apply(lambda x: tree2conlltags(x)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XipaD_najhNj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_liar_train['new_context'] = df_liar_train['context'].apply(lambda x:  nltk.ne_chunk(pos_tag(word_tokenize(str(x))))) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t23lP6IRlM-d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_liar_train[['iob_tagged_context', 'new_context', 'context']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3dJdXaGgrtD",
        "colab_type": "text"
      },
      "source": [
        "Use TF-Idf vectorizer to vectorize the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzeuBZzC4yqz",
        "colab_type": "text"
      },
      "source": [
        "# LDA Modelling and Topic Naming"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZbHjvl8UdIF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_liar_train['index'] = df_liar_train.index\n",
        "data = df_liar_train\n",
        "train_lda = data[['clean', 'index']]\n",
        "train_lda.head(4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFc0O2coUdIH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_liar_test['index'] = df_liar_test.index\n",
        "data = df_liar_test\n",
        "test_lda = data[['clean', 'index']]\n",
        "test_lda.head(4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYwgcwV6UdIJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_liar_val['index'] = df_liar_val.index\n",
        "data = df_liar_val\n",
        "valid_lda = data[['clean', 'index']]\n",
        "valid_lda.head(4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qtrxq45mUdIL",
        "colab_type": "text"
      },
      "source": [
        "#### Split the clean news into list of words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqeZ3fyMUdIL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "processed_docs = train_lda['clean'].map(lambda doc: doc.split(\" \"))\n",
        "processed_docs[:4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8l8JGyVqUdIN",
        "colab_type": "text"
      },
      "source": [
        "### Latent Dirichlet Allocation (LDA)\n",
        "\n",
        "> It is an example of a probabilistic topic model. Topic models are a great way to automatically explore and structure a large set of documents: they group or cluster documents based on the words that occur in them. As documents on similar topics tend to use a similar sub-vocabulary, the resulting clusters of documents can be interpreted as discussing different 'topics'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QI9FZcp5UdIN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_word_tokens(text):\n",
        "    result = []\n",
        "    for token in gensim.utils.simple_preprocess(text):\n",
        "        if len(token) > 3:\n",
        "            result.append(token)\n",
        "    return result\n",
        "tokenized_docs_local = df_liar_train['clean'].map(get_word_tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNGQFw3NUdIP",
        "colab_type": "text"
      },
      "source": [
        "### Create a function to build the dictionary and tokenized docs for given feature\n",
        "\n",
        "Below function does the following\n",
        "* #### Dictionary\n",
        "Returns Dictionary given, dataframe and column name\n",
        "* #### Tokenizeddocs\n",
        "Returns Tokenizeddocs, of the all the words in a text in that column can be used for bow_corpus\n",
        "* #### Dictionary is filtered using Gensim filter_extremes\n",
        "    Filter out tokens that appear in less than 15 documents (absolute number) or more than 0.5 documents (fraction of total corpus size, not absolute number). after the above two steps, keep only the first 100000 most frequent tokens.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2gO-oJGUdIQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_dictionary_print_words(dataframe,colname):\n",
        "    dictionary_gensim = gensim.corpora.Dictionary(processed_docs)\n",
        "    count = 0\n",
        "    print('######## DICTIONARY Words and occurences ########')\n",
        "    for k, v in dictionary_gensim.iteritems():\n",
        "        print(k, v)\n",
        "        count += 1\n",
        "        if count > 10:\n",
        "            break\n",
        "    dictionary_gensim.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)\n",
        "    return dictionary_gensim, tokenized_docs_local"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWIzKTxrUdIS",
        "colab_type": "text"
      },
      "source": [
        "#### Gensim filter_extremes\n",
        "\n",
        "> Filter out tokens that appear less than 15 documents (absolute number) or more than 0.5 documents (fraction of total corpus size, not absolute number). after the above two steps, keep only the first 100000 most frequent tokens."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PitvRKZ5UdIS",
        "colab_type": "text"
      },
      "source": [
        "#### Create a function to build bow_corpus from dictionary and tokenized_docs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6dGqMuuUdIS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_bow_corpus_print_sample(dataframe,colname):\n",
        "    dictionary_gensim, tokenized_docs_local = get_dictionary_print_words(dataframe, colname)\n",
        "    bow_corpus_local = [dictionary_gensim.doc2bow(doc) for doc in tokenized_docs_local]\n",
        "    bow_doc_local_0 = bow_corpus_local[0]\n",
        "    print('\\n ######## BOW VECTOR FIRST ITEM ########')\n",
        "    print(bow_doc_local_0)\n",
        "    print('\\n ######## PREVIEW BOW ########')\n",
        "    for i in range(len(bow_doc_local_0)):\n",
        "        print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_local_0[i][0], \n",
        "                                               dictionary_gensim[bow_doc_local_0[i][0]], bow_doc_local_0[i][1]))\n",
        "    return bow_corpus_local, dictionary_gensim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqNSZxbWUdIV",
        "colab_type": "text"
      },
      "source": [
        "**Gensim doc2bow**\n",
        "\n",
        "For each document we create a dictionary reporting how many words and how many times those words appear. Save this to ‘bow_corpus’, then check our selected document earlier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6_Yl0oiUdIV",
        "colab_type": "text"
      },
      "source": [
        "#### Create a function to build tfidf_corpus from bow_corpus\n",
        "\n",
        "Create tf-idf model object using models.TfidfModel on ‘bow_corpus’ and save it to ‘tfidf’, then apply transformation to the entire corpus and call it ‘corpus_tfidf’. Finally we preview TF-IDF scores for our first document."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0njTloz6UdIV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_tfidf_corpus_print_sample(bow_corpus_local):\n",
        "    from gensim import corpora, models\n",
        "    tfidf = models.TfidfModel(bow_corpus_local)\n",
        "    tfidf_corpus_local = tfidf[bow_corpus_local]\n",
        "    print('\\n ######## TFIDF VECTOR FIRST ITEM ########')\n",
        "    \n",
        "    from pprint import pprint\n",
        "    for doc in tfidf_corpus_local:\n",
        "        pprint(doc)\n",
        "        break\n",
        "    return tfidf_corpus_local"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YhB2GjyUdIX",
        "colab_type": "text"
      },
      "source": [
        "#### Create a function to run ldamodel and print top 10 topics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyFU8_L5UdIX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_lda_model_print_top_topics(bow_corpusforlda,numtopics,dictionaryforlda):\n",
        "    lda_model = gensim.models.LdaMulticore(bow_corpusforlda, num_topics=numtopics, id2word=dictionaryforlda, passes=2, workers=2)\n",
        "    lda_all_topics=lda_model.show_topics(num_topics=numtopics, num_words=10,formatted=False)\n",
        "    lda_topics_words = [(tp[0], [wd[0] for wd in tp[1]]) for tp in lda_all_topics]\n",
        "\n",
        "    #Below Code Prints Topics and Words\n",
        "    for topic,words in lda_topics_words:\n",
        "        print(str(topic)+ \"::\"+ str(words))\n",
        "    return lda_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdRkEPiWUdIZ",
        "colab_type": "text"
      },
      "source": [
        "#### Create a function to run ldamodel and print top 10 topics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIKxRzDVUdIa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_lda_model_topics_topwords_print_top_topics(bow_corpusforlda,numtopics,dictionaryforlda):\n",
        "    lda_model = gensim.models.LdaMulticore(bow_corpusforlda, num_topics=numtopics, id2word=dictionaryforlda, passes=2, workers=2, random_state=1)\n",
        "    lda_all_topics=lda_model.show_topics(num_topics=numtopics, num_words=10,formatted=False)\n",
        "    lda_topics_words = [(tp[0], [wd[0] for wd in tp[1]]) for tp in lda_all_topics]\n",
        "\n",
        "    #Below Code Prints Topics and Words\n",
        "    for topic,words in lda_topics_words:\n",
        "        print(str(topic)+ \"::\"+ str(words))\n",
        "    return lda_model,lda_topics_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ECl8SJHUdIc",
        "colab_type": "text"
      },
      "source": [
        "#### Create a function to enrich data with lda topics, lda topics score, top words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a0sDPj7UdId",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def identify_topic_number_score_label_topwords(text,dictionary_local,lda_model_local,lda_topics_top_words_local):\n",
        "    bow_vector_local = dictionary_local.doc2bow(get_word_tokens(text))\n",
        "    topic_number_local, topic_score_local = sorted(\n",
        "        lda_model_local[bow_vector_local], key=lambda tup: -1*tup[1])[0]\n",
        "    #print (topic_number_local, topic_score_local)\n",
        "    return pd.Series([topic_number_local, topic_score_local,\" \".join(lda_topics_top_words_local[int(topic_number_local)][1])])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kqdmCG2UdIf",
        "colab_type": "text"
      },
      "source": [
        "#### Create a function that can enrich topic data to dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fD8ghFVdUdIf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def update_lda_results_to_dataset(dataframe,topiccolnames,coltoapplylda,colnamedictionary,colnameldamodel, colnameldatopwords):\n",
        "    dataframe[topiccolnames] = dataframe.apply(\n",
        "    lambda row: identify_topic_number_score_label_topwords(\n",
        "        row[coltoapplylda],colnamedictionary,colnameldamodel,\n",
        "        colnameldatopwords), axis=1)\n",
        "    return dataframe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2QxCYNDUdIh",
        "colab_type": "text"
      },
      "source": [
        "### Bag of Words\n",
        "\n",
        "#### Create a dictionary and tokens\n",
        "\n",
        "> Create a dictionary from ‘processed_docs’ containing the number of times a word appears in the training set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCmZuhqxUdIh",
        "colab_type": "text"
      },
      "source": [
        "#### Create a function to convert text to word tokens from cleaned dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvdgbJ5NUdIi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bow_corpus_headline, dictionary_headline = get_bow_corpus_print_sample(df_liar_train,\n",
        "                                                                      'clean')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GS4T84a3UdIk",
        "colab_type": "text"
      },
      "source": [
        "### Running LDA using Bag of Words\n",
        "Train our lda model using gensim.models.LdaMulticore and save it to ‘lda_model’"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGSj012yUdIk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lda_model_headline, lda_headline_topic_words = get_lda_model_topics_topwords_print_top_topics(\n",
        "    bow_corpus_headline, 10 ,dictionary_headline)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMloBhaNUdIm",
        "colab_type": "text"
      },
      "source": [
        "#### Generate TF-IDF bow_corpus\n",
        "Create tf-idf model object using models.TfidfModel on ‘bow_corpus’ and save it to ‘tfidf’, then apply transformation to the entire corpus and call it ‘corpus_tfidf’. Finally we preview TF-IDF scores for our first document."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4Et3v2OUdIm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfidf_corpus_headline = get_tfidf_corpus_print_sample(bow_corpus_headline)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QwFx4X1UdIs",
        "colab_type": "text"
      },
      "source": [
        "### Running LDA model using Bag of Words\n",
        "Train our lda model using gensim.models.LdaMulticore and save it to ‘lda_model’\n",
        "\n",
        "**GOAL**: To get top ten topics with top words. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "hslxpOGUUdIs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lda_tfidf_model_headline  = get_lda_model_print_top_topics(tfidf_corpus_headline,10,dictionary_headline)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZReHy8aUdIu",
        "colab_type": "text"
      },
      "source": [
        "#### Explanation for LDA \n",
        "![[Explanation of LDA](http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1508239587/n4ZpIXl_egq7mq.png)](http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1508239587/n4ZpIXl_egq7mq.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjoIQc3NUdIu",
        "colab_type": "text"
      },
      "source": [
        "### Semisupervised Labeling\n",
        "Based on train,test and valid data explored the topic scores for sample data and identified below topics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMxnKB1gUdIv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "semisupervised_topic_labels = ['topic0','topic1','topic2','topic3','topic4','topic5','topic6','topic7','topic8','topic9']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXiInP2YUdIx",
        "colab_type": "text"
      },
      "source": [
        "####  Function to add topicnumber, topicscore, topiclabel, topwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2z3GQ08_UdIx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "headlinetopiccolnames = ['topic_number','lda_score','topic_top_words']\n",
        "df_liar_train = update_lda_results_to_dataset(\n",
        "    df_liar_train, headlinetopiccolnames,'clean', dictionary_headline, lda_model_headline, lda_headline_topic_words)\n",
        "df_liar_train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_H8C-pFMUdI0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_liar_test = update_lda_results_to_dataset(\n",
        "    df_liar_test,headlinetopiccolnames,'clean',\n",
        "  dictionary_headline,lda_model_headline,lda_headline_topic_words)\n",
        "df_liar_test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESlC_MPFUdI3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_liar_val = update_lda_results_to_dataset(\n",
        "    df_liar_val,headlinetopiccolnames,'clean',\n",
        "  dictionary_headline,lda_model_headline,lda_headline_topic_words)\n",
        "df_liar_val.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nN0y5iinUdI6",
        "colab_type": "text"
      },
      "source": [
        "### Visualize the LDA Distribution of news against Top 10 Topics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wK1VrvuIUdI6",
        "colab_type": "text"
      },
      "source": [
        "**GOAL 1:** *Each of the N documents will be represented in the LDA model by a vector of length M*\n",
        "**GOAL 2:** *Each of the M topics is represented by a vector of length V*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3ac50YaUdI7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import seaborn as sb\n",
        "def create_distribution(dataFile):\n",
        "    g = sb.countplot(x='topic_number', data=dataFile, palette='hls')\n",
        "    g.set_xticklabels(g.get_xticklabels(),rotation=90)\n",
        "\n",
        "    return g\n",
        "\n",
        "create_distribution(df_liar_train) # TRAIN Document Vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "exuEd3L5UdI8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "create_distribution(df_liar_test)# TEST Document Vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "A5kU_ZhOUdI9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "create_distribution(df_liar_val)# VALID Document Vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvZGOUgOUdI_",
        "colab_type": "text"
      },
      "source": [
        "##### Saved the latest dataset into a seperate CSV file "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FD-swxBXUdJA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_news.to_csv(\"/content/gdrive/My Drive/MLSpring2020/datatribe-nutritionbasediseaseprediction/AlternusVera/Datasets/train_lda.csv\", sep=',')\n",
        "test_news.to_csv(\"/content/gdrive/My Drive/MLSpring2020/datatribe-nutritionbasediseaseprediction/AlternusVera/Datasets/test_lda.csv\", sep=',')\n",
        "valid_news.to_csv(\"/content/gdrive/My Drive/MLSpring2020/datatribe-nutritionbasediseaseprediction/AlternusVera/Datasets/valid_lda.csv\", sep=',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlbMBdv8Nwva",
        "colab_type": "text"
      },
      "source": [
        "## Let us check the accuracies using the LDA score as X and label as Y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sii8w5LvOaik",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "true_labels = ['original','true','mostly-true','half-true']\n",
        "false_labels = ['barely-true','false','pants-fire']\n",
        "def simplify_label(input_label):\n",
        "    if input_label == 'original':\n",
        "        return 1\n",
        "    elif input_label == 'true':\n",
        "        return 1\n",
        "    elif input_label == 'mostly-true':\n",
        "        return 1\n",
        "    elif input_label == 'half-true':\n",
        "        return 0\n",
        "    elif input_label == 'barely-true':\n",
        "        return 0\n",
        "    elif input_label == 'false':\n",
        "        return 0\n",
        "    elif input_label == 'pants-fire':\n",
        "        return 0\n",
        "\n",
        "labelcolname = 'encoded_label'\n",
        "\n",
        "df_liar_train[labelcolname] = df_liar_train.apply(lambda row: simplify_label(row['label']), axis=1)\n",
        "df_liar_test[labelcolname] = df_liar_test.apply(lambda row: simplify_label(row['label']), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpLlzBJ4HcT9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = df_liar_train['lda_score'].values.reshape(-1, 1)\n",
        "Y_train = df_liar_train['encoded_label'].values.reshape(-1, 1)\n",
        "X_test = df_liar_test['lda_score'].values.reshape(-1, 1)\n",
        "Y_test = df_liar_test['encoded_label'].values.reshape(-1, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZmEuS9xZOY17"
      },
      "source": [
        " **Naive Bayes Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R5qQi5-aOY2A",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plot\n",
        "\n",
        "NBClassifier(X_train, Y_train, X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "B-1LIlUnOY2F"
      },
      "source": [
        "**Decision Tree Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D0URl8GUOY2G",
        "colab": {}
      },
      "source": [
        "DTreesClassifier(X_train, Y_train, X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mhsAp1a8OY2I"
      },
      "source": [
        "**Support Vector Machines**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-NAASAlTOY2J",
        "colab": {}
      },
      "source": [
        "SVMClassifier(X_train, Y_train, X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0dxeU7HaOY2M"
      },
      "source": [
        "**Linear Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ImZKmNWUOY2M",
        "colab": {}
      },
      "source": [
        "LinRegClassifier(X_train, Y_train, X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0SDicbyTOY2O"
      },
      "source": [
        "**Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "14f58DWFOY2P",
        "colab": {}
      },
      "source": [
        "LogRegression(X_train, Y_train, X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FG0a6lJXqxJl",
        "colab_type": "text"
      },
      "source": [
        "# Amalgamation of Liar Liar and Kaggle Fake News dataset - using Cosine Similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iH9GzetI73NK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Kaggle fake news dataset\n",
        "df_fake_train = pd.read_csv(\"/content/gdrive/My Drive/MLSpring2020/datatribe-nutritionbasediseaseprediction/AlternusVera/Datasets/fake_news/train.csv\")\n",
        "df_fake_test = pd.read_csv(\"/content/gdrive/My Drive/MLSpring2020/datatribe-nutritionbasediseaseprediction/AlternusVera/Datasets/fake_news/test.csv\")\n",
        "df_fake_sub = pd.read_csv(\"/content/gdrive/My Drive/MLSpring2020/datatribe-nutritionbasediseaseprediction/AlternusVera/Datasets/fake_news/submit.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8enLBWAPzY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_fake_train.text[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_osK9a1yQCHV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_liar_train.headline_text[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcQmZ7Z8PaIz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "corpusLiar = []\n",
        "for i in df_liar_train['headline_text']:\n",
        "    corpusLiar.append(i)\n",
        "\n",
        "corpusFake = []\n",
        "for i in df_fake_train['text'].astype('U'):\n",
        "    corpusFake.append(i)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2KI-xyY9KNG",
        "colab_type": "text"
      },
      "source": [
        "Train a classifier that predicts the fakeness in the range of classes given by liar liar dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pA5TGWyM9JJu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidfVec = TfidfVectorizer(max_features=1000)\n",
        "\n",
        "tfidf_liar = tfidfVec.fit_transform(corpusLiar)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxJ1t_RE8pDm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf_idf_fakenews = tfidfVec.fit_transform(corpusFake)\n",
        "words = tfidfVec.get_feature_names()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1bdCaY1UVzX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfidf_liar.toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5Yj0MJEUcG1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf_idf_fakenews.toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZON188RUhVk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfidfVec.vocabulary_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYb9S3lyUy0X",
        "colab_type": "text"
      },
      "source": [
        "**Cosine Similarity**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huOeuN0rWuFr",
        "colab_type": "text"
      },
      "source": [
        "Liar Liar dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1W1vD7EFVL0f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_tfidf = tfidfVec.fit_transform(df_liar_train['headline_text'])\n",
        "print('Training dim:', train_tfidf.shape)\n",
        "print(train_tfidf.A[:10])\n",
        "\n",
        "\n",
        "# test_tfidf = tfidfVec.fit_transform(df_liar_test['statement'])\n",
        "# print('Test dim:', test_tfidf.shape)\n",
        "# print(test_tfidf.A[:10])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMeZMU9zVaa7",
        "colab_type": "text"
      },
      "source": [
        "cosine similarity of Training data for liar liar dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abgCVhwnUq3x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy import spatial\n",
        "similarity_score = []\n",
        "for i in range(len(train_tfidf.toarray())):\n",
        "    similarity_score.append(1 - spatial.distance.cosine(tf_idf_fakenews[0].toarray(), tfidf_liar[i].toarray()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvWth5mKV36R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#append the similarity_score to both liar liar dataset and kaggle fake news dataset for amalgamation\n",
        "df_liar_train['cosine_score'] = similarity_score\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BL7dBUbZWzUB",
        "colab_type": "text"
      },
      "source": [
        "Kaggle fake news dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dM3EbQsJW2Ez",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "similarity_score_fake = []\n",
        "for i in range(len(tf_idf_fakenews.toarray())):\n",
        "    similarity_score_fake.append(1 - spatial.distance.cosine(tfidf_liar[0].toarray(), tf_idf_fakenews[i].toarray()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUSL_QqhYHhY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_fake_train['cosine_score'] = similarity_score_fake"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLiq0gBiZCEG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_liar_train = df_liar_train.dropna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fo9YkDRLbVmx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_liar_train.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgy-HQZfaUx7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_fake_train = df_fake_train.dropna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efnGP4hVkTGL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_liar_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1qWozojkWVi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_fake_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mWRQBhok_3q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_liar_train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3ORqndAYNru",
        "colab_type": "text"
      },
      "source": [
        "Amalgamtion of the two datasets - liar liar and kaggle fake news"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftkY8NvenVYR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def simplify_label(input_label):\n",
        "    if input_label in true_labels:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aq09KDnMYTpy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_amal = df_liar_train.merge(df_fake_train, on=\"cosine_score\", how=\"inner\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYCyv1K7Y1_E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_amal.dropna(axis=0, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eFgnKWBpcqb",
        "colab_type": "text"
      },
      "source": [
        "# Data Enrichment - Adding a new column called Authenticity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuvkxHfK1sbW",
        "colab_type": "text"
      },
      "source": [
        "This distillation step involves creating a new column of authenticity based on the source of the statement."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vjvI_Te0zf3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "true_labels = ['original','true','mostly-true','half-true']\n",
        "false_labels = ['barely-true','false','pants-fire']\n",
        "def simplify_label(input_label):\n",
        "    if input_label in true_labels:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUgf1Shp1xVR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labelcolname = 'encoded_label'\n",
        "\n",
        "df_liar_train[labelcolname] = df_liar_train.apply(lambda row: simplify_label(row['label']), axis=1)\n",
        "df_liar_test[labelcolname] = df_liar_test.apply(lambda row: simplify_label(row['label']), axis=1)\n",
        "df_liar_val[labelcolname] = df_liar_val.apply(lambda row: simplify_label(row['label']), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZ40aSIa5vSG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "true_labels = ['news','interview','television','show', 'speech', 'reporters', 'debate', 'newsletter', 'press', 'CNN', 'ABC', 'CBS', 'video', 'conference', 'official', 'book']\n",
        "false_labels = ['website', 'tweet', 'mail', 'e-mail', 'mailer', 'web', 'site', 'meme', 'comic', 'advertisement', 'ad', 'blog', 'flier', \n",
        "                'letter', 'social', 'tweets', 'internet', 'message', 'campaign', 'post', 'facebook', 'handout', 'leaflet', 'letter' ]\n",
        "def simplify_venue_label(input_label):\n",
        "    words = input_label.split(\" \")\n",
        "    for s in words:\n",
        "      if s in true_labels:\n",
        "        return 1\n",
        "      elif s in false_labels:\n",
        "        return 0\n",
        "    else:\n",
        "        return 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3kEY25i5zYN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labelcolname = 'authenticity'\n",
        "\n",
        "df_liar_train[labelcolname] = df_liar_train.apply(lambda row: simplify_venue_label(str(row['context'])), axis=1)\n",
        "df_liar_test[labelcolname] = df_liar_test.apply(lambda row: simplify_venue_label(str(row['context'])), axis=1)\n",
        "df_liar_val[labelcolname] = df_liar_val.apply(lambda row: simplify_venue_label(str(row['context'])), axis=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywMtq7AG51zq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "obj = [df_liar_train, df_liar_val]\n",
        "df_train = pd.concat(obj)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hJwZOpn53qu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = df_train['authenticity'].values.reshape(-1, 1)\n",
        "Y_train = df_train['encoded_label'].values\n",
        "X_test = df_liar_test['authenticity'].values.reshape(-1, 1)\n",
        "Y_test = df_liar_test['encoded_label'].values.reshape(-1, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VijcBpoqIig",
        "colab_type": "text"
      },
      "source": [
        "## running the classification algorithms with this newly added column as X and label as Y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "249keGWTquT4"
      },
      "source": [
        " **Naive Bayes Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rLRneWH_quT4",
        "colab": {}
      },
      "source": [
        "NBClassifier(X_train, Y_train, X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GhED5QjlquT7"
      },
      "source": [
        "**Decision Tree Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "urhyA96wquT8",
        "colab": {}
      },
      "source": [
        "DTreesClassifier(X_train, Y_train, X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Lu6_dO33quT-"
      },
      "source": [
        "**Support Vector Machines**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WNwXH221quT-",
        "colab": {}
      },
      "source": [
        "SVMClassifier(X_train, Y_train, X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ANh3DTa9quUA"
      },
      "source": [
        "**Linear Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eX5B4We0quUA",
        "colab": {}
      },
      "source": [
        "LinRegClassifier(X_train, Y_train, X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y1B8PWF4quUC"
      },
      "source": [
        "**Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "snZlv-UQquUC",
        "colab": {}
      },
      "source": [
        "LogRegression(X_train, Y_train, X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9O1bXuTRmCi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZDLXr_NRqG-",
        "colab_type": "text"
      },
      "source": [
        "# Polynomial Equation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5lPNll4LO5Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  X_train = df_train['authenticity'].values.reshape(-1, 1)\n",
        "  Y_train = df_train['encoded_label'].values\n",
        "  X_test = df_liar_test['authenticity'].values.reshape(-1, 1)\n",
        "  Y_test = df_liar_test['encoded_label'].values.reshape(-1, 1)\n",
        "  \n",
        "  model = SVC()\n",
        "  model.fit(X_train,Y_train)\n",
        "  predicted = model.predict(X_test)\n",
        "  print(classification_report(Y_test, predicted))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTYhLb4Grqrr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def DATATRIBE_getAuthenticityScoreBySource(src):\n",
        "  x = simplify_venue_label(src)\n",
        "  xTrain = np.array(x).reshape(-1, 1)\n",
        "\n",
        "  xPpredicted = model.predict(xTrain)\n",
        "  xPredicedProb = logClassifier.predict_proba(xTrain)[:,1]\n",
        "  return 1 - float(xPredicedProb)\n",
        "\n",
        "print(DATATRIBE_getAuthenticityScoreBySource('news'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gd3bq78n1tnl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def isFakeNews(headline=\"\", source = \"\", speaker =\"\",context =\"\"):\n",
        "    accur = [0.58, 0.52, 0.56] # using the (normalized) accuracy as weigths\n",
        "    w = [float(i)/sum(accur) for i in accur]\n",
        "    sumW = 0\n",
        "    prob = []\n",
        "    # if ( (headline != \"\") & (speaker != \"\")):\n",
        "    #     prob.append(w[0] * DATATRIBE_getEventCoverageScore(headline,speaker))\n",
        "    #     sumW += w[0]\n",
        "    # if ((context != \"\") & (speaker != \"\")):\n",
        "    #     prob.append(w[1] * DATATRIBE_getReliableSource(context,speaker))\n",
        "    #     sumW += w[1]\n",
        "    if (source != \"\"):\n",
        "        prob.append(w[2] * DATATRIBE_getAuthenticityScoreBySource(source))\n",
        "        sumW += w[2]\n",
        "    probTotal = sum(prob[0:len(prob)]) / sumW\n",
        "    return probTotal\n",
        "    \n",
        "result = isFakeNews(\"Says the Annies List political group supports third-trimester abortions on demand.\", \"news\", \"barack-obama\",\"a news release\")\n",
        "print(result)\n",
        "if result > 0.5:\n",
        "    print(\"is FAKE NEWS!!!\")\n",
        "else:\n",
        "    print(\"it is NOT fake news!!!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFopV4cWRn-4",
        "colab_type": "text"
      },
      "source": [
        "# Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYTaj0YaLu8g",
        "colab_type": "text"
      },
      "source": [
        "**Multiclass classification results**\n",
        "We first modeled the data with a baseline model and the accuracies obtained are as below:\n",
        "- Logistic Regression: 0.24230465666929754\n",
        "- SVM: 0.23914759273875297\n",
        "- Naive Bayes: 0.24230465666929754\n",
        "- Random Forests0.27466456195737965\n",
        "\n",
        "\n",
        " we added a new feature called authenticity to our dataset which we enriched manually. This gave the below results:\n",
        "- Naive Bayes= 0.58\n",
        "- Decision Trees = 0.56\n",
        "- SVM = 0.55\n",
        "- Regression = 0.56\n",
        "\n",
        "Next, we tried the process of distillation like LDA, NER and amalgamation with Kaggle fake news dataset to enrich our dataset. The accuracies improved to these scores:\n",
        "- Naive Bayes= 0.65\n",
        "- Decision Trees = 0.55\n",
        "- SVM = 0.55\n",
        "- Regression = 0.66\n",
        "\n",
        "Thus, we can see that multiclass classification benefits from enrichments made to the dataset. Processes like distillation, NER, LDA, word embeddings help to bring out the important features and model better and improve accuracy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrhuudnyMJp4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}